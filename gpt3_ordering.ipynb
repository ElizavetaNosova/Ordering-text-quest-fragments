{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt3_ordering.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMIsC3RK/9zEM84bgC0DSut",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElizavetaNosova/Ordering-text-quest-fragments/blob/main/gpt3_ordering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD92R0HM59KK"
      },
      "source": [
        "#from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "from networkx.readwrite import json_graph\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from copy import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TogQbN6Q1sdi"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQ2QELfvRFMP",
        "outputId": "224fdcf4-00ee-4378-af89-27c0d8a9461f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eQIG2J-RJBl"
      },
      "source": [
        "os.chdir('gdrive/MyDrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeTGypW9KEJU"
      },
      "source": [
        "MODEL_PATH = \"home/jovyan/devices/quests/hf\"\n",
        "TOKENIZER_PATH = \"home/jovyan/devices/quests/hf\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S66wZkoKS3V"
      },
      "source": [
        "gpt_model = GPT2LMHeadModel.from_pretrained(MODEL_PATH)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(TOKENIZER_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y70Ut9eFNKzW"
      },
      "source": [
        "gpt_model.cuda()\n",
        "gpt_model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkYZI1-h9A9y"
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + math.exp(-x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XhnHy2L6DPv"
      },
      "source": [
        "GPT3_LIMIT = 2048\n",
        "FULL_LIMIT = 1500\n",
        "def calc_perplexity_based_score(history_tokens, next_candidate_tokens, candidate_limit=500): \n",
        "    history_limit = FULL_LIMIT-min(candidate_limit, len(next_candidate_tokens))\n",
        "    sequence_tokens = history_tokens[-history_limit:] + next_candidate_tokens[:candidate_limit]\n",
        "\n",
        "    input_idx = torch.tensor([sequence_tokens])\n",
        "    input_idx = input_idx.cuda()\n",
        "    with torch.no_grad():\n",
        "        loss = float(gpt_model(input_idx, labels=input_idx)[0].cpu())\n",
        "    return 1-sigmoid(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ-H7ueP-kvg"
      },
      "source": [
        "start_token = 'BOQ'\n",
        "\n",
        "class Fragment:\n",
        "    bof_token = 'BOF'\n",
        "    button_token = 'BUTTON'\n",
        "    input_token = 'INPUT'\n",
        "    default_input='Далее'\n",
        "\n",
        "    def __init__(self, fragment_id, graph=None, full_text = None):\n",
        "        self.fragment_id = fragment_id\n",
        "        if graph:\n",
        "            fragment_text = graph.nodes()[fragment_id]['fragment_text']\n",
        "            edges = graph.edges()\n",
        "            buttons =  [' '.join([self.button_token, edges[edge]['command']] + [self.default_input]) for edge in graph.out_edges(fragment_id)]\n",
        "            full_text = ' '.join([self.bof_token, fragment_text]) \n",
        "            if buttons:\n",
        "                full_text = full_text + ' '.join(buttons)\n",
        "        full_text = ' '.join([full_text, self.input_token, self.default_input])\n",
        "        self.tokens = tokenizer.encode(full_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpfS6_WjCMmz"
      },
      "source": [
        "NEW_GRAPHS_DIRECTORY = 'new_questbook_graphs'\n",
        "NEW_PATHS_DIRECTORY = 'new_questbook_paths'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBnmCTkYILZA"
      },
      "source": [
        "def gpt_beam_search(test_sample, quest_graph, num_best_candidates=2):\n",
        "    fragments = [Fragment(node_id, quest_graph) for node_id in test_sample]\n",
        "    \n",
        "    order_candidates = [{'beginning':[], 'next_candidates': fragments, 'probability':1, 'history':tokenizer.encode(start_token)}]\n",
        "    random.shuffle(order_candidates[0]['next_candidates'])\n",
        "    \n",
        "    for i in range(len(fragments)):\n",
        "        current_iteration_next_candidates = []\n",
        "        \n",
        "        for order_candidate in order_candidates:\n",
        "            history = order_candidate ['history']\n",
        "            \n",
        "            \n",
        "            scored_next = [{'next_fragment':next_fragment, 'score':calc_perplexity_based_score(history, next_fragment.tokens)} for next_fragment in order_candidate['next_candidates']]\n",
        "            scored_next.sort(key=lambda x: x['score'], reverse=True)\n",
        "            \n",
        "            chosen_next_candidates = scored_next[:num_best_candidates] if len(scored_next) < num_best_candidates else scored_next\n",
        "            for chosen_next_candidate in chosen_next_candidates:\n",
        "                \n",
        "                next_step_beginning = copy(order_candidate['beginning'])\n",
        "                next_step_beginning.append(chosen_next_candidate['next_fragment'])\n",
        "                \n",
        "                next_step_probability = order_candidate['probability']*chosen_next_candidate['score']\n",
        "                \n",
        "                next_step_next_candidates = []\n",
        "                for next_step_next_candidate in order_candidate['next_candidates']:\n",
        "                    if next_step_next_candidate.fragment_id != chosen_next_candidate['next_fragment'].fragment_id:\n",
        "                        next_step_next_candidates.append(next_step_next_candidate)\n",
        "                next_step_history = history + chosen_next_candidate['next_fragment'].tokens\n",
        "                \n",
        "              \n",
        "                current_iteration_next_candidates.append({'beginning':next_step_beginning, 'next_candidates':next_step_next_candidates, 'probability':next_step_probability, 'history': next_step_history})\n",
        "        \n",
        "        current_iteration_next_candidates.sort(key=lambda x: x['probability'], reverse=True)\n",
        "       # print(len(current_iteration_next_candidates))\n",
        "        if current_iteration_next_candidates:\n",
        "            order_candidates = current_iteration_next_candidates[:num_best_candidates] if len(current_iteration_next_candidates) > num_best_candidates else  current_iteration_next_candidates\n",
        "    return [fragment.fragment_id for fragment in order_candidates[0]['beginning']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9z5hRgpNP0r"
      },
      "source": [
        "results = []\n",
        "fails = []\n",
        "for file_name in tqdm(os.listdir(NEW_GRAPHS_DIRECTORY)[3:]):\n",
        "    used_current_file_paths = 0\n",
        "    graph_file = os.path.join(NEW_GRAPHS_DIRECTORY, file_name)\n",
        "    with open(graph_file) as f:\n",
        "        G = json_graph.node_link_graph(json.load(f))\n",
        "        nodes = G.nodes()\n",
        "\n",
        "    paths_file = os.path.join(NEW_PATHS_DIRECTORY, file_name)\n",
        "    with open(paths_file) as f:\n",
        "        paths = json.load(f)\n",
        "    \n",
        "    for path in paths:\n",
        "        corrected_path = [node_id for node_id in path if 'fragment_text' in nodes[node_id] and isinstance(nodes[node_id]['fragment_text'], str)]\n",
        "        if len(corrected_path) > 3 and len(corrected_path) <= 25:\n",
        "            try:\n",
        "                predicted = gpt_beam_search(corrected_path, G)\n",
        "\n",
        "                results.append({'correct':path, 'predicted':predicted})\n",
        "                used_current_file_paths += 1\n",
        "                if len(results) % 10 == 0:\n",
        "                    with open('gpt3_ordering_1500.json', 'w') as f:\n",
        "                        json.dump(results, f)\n",
        "                if used_current_file_paths == 10:\n",
        "                    break\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "                \n",
        "with open('gpt3_ordering_1500.json', 'w') as f:\n",
        "    json.dump(results, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIy3Ln4EUb-y"
      },
      "source": [
        "# The first sequences were generated without the last iteration by mistake\n",
        "def fix_prediction(predicted, correct):\n",
        "    if len(predicted) == len(correct):\n",
        "        return predicted\n",
        "    elif len(predicted) < len(correct):\n",
        "        unordered_items = [item for item in correct if item not in predicted]\n",
        "        random.shuffle(unordered_items)\n",
        "        return predicted + unordered_items\n",
        "    else:\n",
        "        raise ValueError('wrong sequence length')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OFkQScROrFR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLNUmWv_YzIU"
      },
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import kendalltau\n",
        "\n",
        "def longest_correct_subsequence(predicted, correct):\n",
        "    correct_transitions = set([(item_from, item_to) for item_from, item_to in zip(correct[:-1], correct[1:])])\n",
        "    predicted_transitions = [(item_from, item_to) for item_from, item_to in zip(predicted[:-1], predicted[1:])]\n",
        "    predicted_transitions_are_correct = [transition in correct_transitions for transition in predicted_transitions]\n",
        "    \n",
        "    longest_correct_transitions_subsequence = 0\n",
        "    current_correct_transitions_subsequence = 0\n",
        "    #Add False as last item to include last real item checking into the loop\n",
        "    for predicted_transition_is_correct in predicted_transitions_are_correct + [False]:\n",
        "        if predicted_transition_is_correct:\n",
        "            current_correct_transitions_subsequence += 1\n",
        "        else:\n",
        "            if current_correct_transitions_subsequence > longest_correct_transitions_subsequence:\n",
        "                longest_correct_transitions_subsequence = current_correct_transitions_subsequence\n",
        "            current_correct_transitions_subsequence = 0\n",
        "    #return number of items in longest correct sequence (not number of transitions)\n",
        "    return longest_correct_transitions_subsequence + 1 if longest_correct_transitions_subsequence else 0  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKJi07-CPwwn"
      },
      "source": [
        "gpt_1500_df = pd.DataFrame(columns=['Fragment_length', 'Tau', 'Max correct sequence'])\n",
        "exceptions = []\n",
        "\n",
        "with open('gpt3_ordering_1500.json') as f:\n",
        "   results = json.load(f)\n",
        "\n",
        "for sample in results:\n",
        "    correct = sample['correct']\n",
        "    try:\n",
        "        predicted = fix_prediction(sample['predicted'], correct)\n",
        "        tau = kendalltau(predicted, correct).correlation\n",
        "        lcs = longest_correct_subsequence(predicted, correct)\n",
        "        gpt_1500_df.loc[len(gpt_1500_df)] = [len(correct), tau, lcs]\n",
        "    except:\n",
        "        exceptions.append(sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7Bi30ogRy1a",
        "outputId": "a64813f4-151d-45a0-d0d6-30f9e2593b67"
      },
      "source": [
        "gpt_1500_df.groupby('Fragment_length').describe().keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiIndex([(                 'Tau', 'count'),\n",
              "            (                 'Tau',  'mean'),\n",
              "            (                 'Tau',   'std'),\n",
              "            (                 'Tau',   'min'),\n",
              "            (                 'Tau',   '25%'),\n",
              "            (                 'Tau',   '50%'),\n",
              "            (                 'Tau',   '75%'),\n",
              "            (                 'Tau',   'max'),\n",
              "            ('Max correct sequence', 'count'),\n",
              "            ('Max correct sequence',  'mean'),\n",
              "            ('Max correct sequence',   'std'),\n",
              "            ('Max correct sequence',   'min'),\n",
              "            ('Max correct sequence',   '25%'),\n",
              "            ('Max correct sequence',   '50%'),\n",
              "            ('Max correct sequence',   '75%'),\n",
              "            ('Max correct sequence',   'max')],\n",
              "           )"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "Y6lozD7SRSK3",
        "outputId": "8dcb28bf-0fc5-430d-c2d7-91b323ee3ade"
      },
      "source": [
        "aggr_gpt1500 = gpt_1500_df.groupby('Fragment_length').describe()[[('Tau',  'count'), ('Tau',  'mean'),  ('Max correct sequence',  'mean')]]\n",
        "aggr_gpt1500"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">Tau</th>\n",
              "      <th>Max correct sequence</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fragment_length</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4.0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5.0</th>\n",
              "      <td>15.0</td>\n",
              "      <td>0.013333</td>\n",
              "      <td>0.866667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6.0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>-0.161905</td>\n",
              "      <td>1.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7.0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>-0.238095</td>\n",
              "      <td>2.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8.0</th>\n",
              "      <td>9.0</td>\n",
              "      <td>-0.079365</td>\n",
              "      <td>2.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9.0</th>\n",
              "      <td>16.0</td>\n",
              "      <td>-0.006944</td>\n",
              "      <td>2.125000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.0</th>\n",
              "      <td>27.0</td>\n",
              "      <td>0.142387</td>\n",
              "      <td>2.074074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11.0</th>\n",
              "      <td>19.0</td>\n",
              "      <td>0.071770</td>\n",
              "      <td>2.105263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12.0</th>\n",
              "      <td>32.0</td>\n",
              "      <td>0.011364</td>\n",
              "      <td>1.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13.0</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.074872</td>\n",
              "      <td>2.240000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14.0</th>\n",
              "      <td>13.0</td>\n",
              "      <td>-0.085376</td>\n",
              "      <td>2.076923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15.0</th>\n",
              "      <td>11.0</td>\n",
              "      <td>-0.075325</td>\n",
              "      <td>2.363636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16.0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>-0.016667</td>\n",
              "      <td>1.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17.0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.009804</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18.0</th>\n",
              "      <td>11.0</td>\n",
              "      <td>0.100416</td>\n",
              "      <td>2.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19.0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.056530</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20.0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.077895</td>\n",
              "      <td>1.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21.0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22.0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.173160</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23.0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.055336</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24.0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.123188</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25.0</th>\n",
              "      <td>10.0</td>\n",
              "      <td>0.119333</td>\n",
              "      <td>1.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26.0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.141538</td>\n",
              "      <td>2.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Tau           Max correct sequence\n",
              "                count      mean                 mean\n",
              "Fragment_length                                     \n",
              "4.0               3.0  0.111111             3.000000\n",
              "5.0              15.0  0.013333             0.866667\n",
              "6.0               7.0 -0.161905             1.857143\n",
              "7.0               6.0 -0.238095             2.666667\n",
              "8.0               9.0 -0.079365             2.444444\n",
              "9.0              16.0 -0.006944             2.125000\n",
              "10.0             27.0  0.142387             2.074074\n",
              "11.0             19.0  0.071770             2.105263\n",
              "12.0             32.0  0.011364             1.687500\n",
              "13.0             25.0  0.074872             2.240000\n",
              "14.0             13.0 -0.085376             2.076923\n",
              "15.0             11.0 -0.075325             2.363636\n",
              "16.0              7.0 -0.016667             1.857143\n",
              "17.0              6.0  0.009804             2.000000\n",
              "18.0             11.0  0.100416             2.090909\n",
              "19.0              6.0  0.056530             1.000000\n",
              "20.0              5.0  0.077895             1.600000\n",
              "21.0              1.0  0.047619             3.000000\n",
              "22.0              2.0 -0.173160             2.000000\n",
              "23.0              2.0 -0.055336             2.000000\n",
              "24.0              2.0  0.123188             1.000000\n",
              "25.0             10.0  0.119333             1.900000\n",
              "26.0              2.0 -0.141538             2.500000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPMiv-a3SHcC"
      },
      "source": [
        "with open('latex.txt', 'w') as f:\n",
        "  f.write(aggr_gpt1500.to_latex())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r151HZyxQEpg",
        "outputId": "74053963-16c3-4476-844d-f4152250d6bd"
      },
      "source": [
        "len(sample['correct'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXODwk_TQO16",
        "outputId": "eec70741-b2a0-4f85-9afa-5b441210544b"
      },
      "source": [
        "len(sample['predicted'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NdBFAppZJT9",
        "outputId": "843af36b-9fde-4166-8d77-0efea6684a7d"
      },
      "source": [
        "FULL_LIMIT = GPT3_LIMIT\n",
        "\n",
        "results = []\n",
        "fails = []\n",
        "for file_name in tqdm(os.listdir(NEW_GRAPHS_DIRECTORY)):\n",
        "    used_current_file_paths = 0\n",
        "    graph_file = os.path.join(NEW_GRAPHS_DIRECTORY, file_name)\n",
        "    with open(graph_file) as f:\n",
        "        G = json_graph.node_link_graph(json.load(f))\n",
        "        nodes = G.nodes()\n",
        "\n",
        "    paths_file = os.path.join(NEW_PATHS_DIRECTORY, file_name)\n",
        "    with open(paths_file) as f:\n",
        "        paths = json.load(f)\n",
        "    \n",
        "    for path in paths:\n",
        "        corrected_path = [node_id for node_id in path if 'fragment_text' in nodes[node_id] and isinstance(nodes[node_id]['fragment_text'], str)]\n",
        "        if len(corrected_path) > 3 and len(corrected_path) <= 25:\n",
        "            try:\n",
        "                predicted = gpt_beam_search(corrected_path, G)\n",
        "\n",
        "                results.append({'correct':path, 'predicted':predicted})\n",
        "                used_current_file_paths += 1\n",
        "                if len(results) % 10 == 0:\n",
        "                    with open('gpt3_ordering_2048.json', 'w') as f:\n",
        "                        json.dump(results, f)\n",
        "                if used_current_file_paths == 10:\n",
        "                    break\n",
        "            except Exception as e:\n",
        "                fails.append[(file_name, e)]\n",
        "                \n",
        "with open('gpt3_ordering_2048.json', 'w') as f:\n",
        "    json.dump(results, f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/34 [00:00<?, ?it/s]\u001b[A\n",
            "  6%|▌         | 2/34 [11:40<3:06:43, 350.12s/it]\u001b[A\n",
            "  9%|▉         | 3/34 [12:56<2:18:25, 267.91s/it]\u001b[A\n",
            " 12%|█▏        | 4/34 [25:07<3:23:27, 406.93s/it]\u001b[A\n",
            " 21%|██        | 7/34 [27:24<2:14:19, 298.51s/it]\u001b[A\n",
            " 24%|██▎       | 8/34 [43:39<3:37:22, 501.62s/it]\u001b[A\n",
            " 26%|██▋       | 9/34 [50:15<3:15:44, 469.78s/it]\u001b[A\n",
            " 32%|███▏      | 11/34 [50:42<2:07:37, 332.92s/it]\u001b[A\n",
            " 35%|███▌      | 12/34 [51:58<1:33:47, 255.81s/it]\u001b[A\n",
            " 38%|███▊      | 13/34 [1:10:20<2:58:26, 509.85s/it]\u001b[A\n",
            " 41%|████      | 14/34 [1:11:31<2:05:59, 378.00s/it]\u001b[A\n",
            " 47%|████▋     | 16/34 [1:16:35<1:33:03, 310.17s/it]\u001b[A\n",
            " 50%|█████     | 17/34 [1:16:42<1:02:08, 219.32s/it]\u001b[A\n",
            " 53%|█████▎    | 18/34 [1:19:23<53:48, 201.76s/it]  \u001b[A\n",
            " 56%|█████▌    | 19/34 [1:24:19<57:31, 230.12s/it]\u001b[A\n",
            " 62%|██████▏   | 21/34 [1:26:42<39:33, 182.58s/it]\u001b[A\n",
            " 68%|██████▊   | 23/34 [1:30:20<29:24, 160.38s/it]\u001b[A\n",
            " 71%|███████   | 24/34 [1:39:07<45:04, 270.45s/it]\u001b[A\n",
            " 76%|███████▋  | 26/34 [1:42:09<28:53, 216.66s/it]\u001b[A\n",
            " 79%|███████▉  | 27/34 [1:45:34<24:52, 213.27s/it]\u001b[A\n",
            " 82%|████████▏ | 28/34 [2:02:23<45:11, 451.88s/it]\u001b[A\n",
            " 88%|████████▊ | 30/34 [2:14:27<28:19, 424.86s/it]\u001b[A\n",
            " 91%|█████████ | 31/34 [2:29:45<28:38, 572.78s/it]\u001b[A\n",
            " 94%|█████████▍| 32/34 [2:37:10<17:49, 534.57s/it]\u001b[A\n",
            " 97%|█████████▋| 33/34 [2:39:17<06:52, 412.22s/it]\u001b[A\n",
            "100%|██████████| 34/34 [2:39:50<00:00, 282.08s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRYwetotbzQO"
      },
      "source": [
        "gpt_2048_df = pd.DataFrame(columns=['Fragment_length', 'Tau', 'Max correct sequence'])\n",
        "exceptions = []\n",
        "\n",
        "with open('gpt3_ordering_2048.json') as f:\n",
        "   results = json.load(f)\n",
        "\n",
        "for sample in results:\n",
        "    correct = sample['correct']\n",
        "    try:\n",
        "        predicted = fix_prediction(sample['predicted'], correct)\n",
        "        tau = kendalltau(predicted, correct).correlation\n",
        "        lcs = longest_correct_subsequence(predicted, correct)\n",
        "        gpt_2048_df.loc[len(gpt_2048_df)] = [len(correct), tau, lcs]\n",
        "    except:\n",
        "        exceptions.append(sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "VfZh8oh0b8xx",
        "outputId": "2e2333cd-bf08-4f5e-dc95-a46bfad58a8c"
      },
      "source": [
        "aggr_gpt2048 = gpt_2048_df.groupby('Fragment_length').describe()[[('Tau',  'count'), ('Tau',  'mean'),  ('Max correct sequence',  'mean')]]\n",
        "aggr_gpt2048"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">Tau</th>\n",
              "      <th>Max correct sequence</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fragment_length</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4.0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>-1.110223e-16</td>\n",
              "      <td>2.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5.0</th>\n",
              "      <td>15.0</td>\n",
              "      <td>1.066667e-01</td>\n",
              "      <td>1.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6.0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>-6.666667e-02</td>\n",
              "      <td>2.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7.0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>-2.698413e-01</td>\n",
              "      <td>2.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8.0</th>\n",
              "      <td>9.0</td>\n",
              "      <td>-8.730159e-02</td>\n",
              "      <td>2.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9.0</th>\n",
              "      <td>16.0</td>\n",
              "      <td>-2.083333e-02</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.0</th>\n",
              "      <td>23.0</td>\n",
              "      <td>1.516908e-01</td>\n",
              "      <td>2.217391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11.0</th>\n",
              "      <td>19.0</td>\n",
              "      <td>9.473684e-02</td>\n",
              "      <td>2.210526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12.0</th>\n",
              "      <td>32.0</td>\n",
              "      <td>1.325758e-02</td>\n",
              "      <td>1.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13.0</th>\n",
              "      <td>21.0</td>\n",
              "      <td>5.006105e-02</td>\n",
              "      <td>2.523810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14.0</th>\n",
              "      <td>13.0</td>\n",
              "      <td>-4.142012e-02</td>\n",
              "      <td>2.153846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15.0</th>\n",
              "      <td>11.0</td>\n",
              "      <td>-9.523810e-03</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16.0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>-7.142857e-03</td>\n",
              "      <td>1.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17.0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>-4.625929e-18</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18.0</th>\n",
              "      <td>8.0</td>\n",
              "      <td>1.225490e-01</td>\n",
              "      <td>1.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19.0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>-8.382066e-02</td>\n",
              "      <td>1.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20.0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>6.315789e-03</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21.0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-3.809524e-02</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22.0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>4.761905e-02</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23.0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>4.347826e-02</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24.0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>6.521739e-02</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25.0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>-6.000000e-02</td>\n",
              "      <td>2.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26.0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-6.769231e-02</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Tau               Max correct sequence\n",
              "                count          mean                 mean\n",
              "Fragment_length                                         \n",
              "4.0               3.0 -1.110223e-16             2.333333\n",
              "5.0              15.0  1.066667e-01             1.200000\n",
              "6.0               7.0 -6.666667e-02             2.142857\n",
              "7.0               6.0 -2.698413e-01             2.666667\n",
              "8.0               9.0 -8.730159e-02             2.666667\n",
              "9.0              16.0 -2.083333e-02             2.000000\n",
              "10.0             23.0  1.516908e-01             2.217391\n",
              "11.0             19.0  9.473684e-02             2.210526\n",
              "12.0             32.0  1.325758e-02             1.750000\n",
              "13.0             21.0  5.006105e-02             2.523810\n",
              "14.0             13.0 -4.142012e-02             2.153846\n",
              "15.0             11.0 -9.523810e-03             2.000000\n",
              "16.0              7.0 -7.142857e-03             1.571429\n",
              "17.0              6.0 -4.625929e-18             1.500000\n",
              "18.0              8.0  1.225490e-01             1.875000\n",
              "19.0              6.0 -8.382066e-02             1.833333\n",
              "20.0              5.0  6.315789e-03             2.000000\n",
              "21.0              1.0 -3.809524e-02             3.000000\n",
              "22.0              2.0  4.761905e-02             1.000000\n",
              "23.0              2.0  4.347826e-02             0.000000\n",
              "24.0              2.0  6.521739e-02             1.000000\n",
              "25.0              5.0 -6.000000e-02             2.400000\n",
              "26.0              2.0 -6.769231e-02             1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oobSHUQcYQf"
      },
      "source": [
        "with open('latex.txt', 'w') as f:\n",
        "  f.write(aggr_gpt1500.to_latex())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R4eVKhegmNs"
      },
      "source": [
        "def gpt_beam_search_last_score(test_sample, quest_graph, num_best_candidates=2):\n",
        "    fragments = [Fragment(node_id, quest_graph) for node_id in test_sample]\n",
        "    \n",
        "    order_candidates = [{'beginning':[], 'next_candidates': fragments, 'probability':1, 'history':tokenizer.encode(start_token)}]\n",
        "    random.shuffle(order_candidates[0]['next_candidates'])\n",
        "    \n",
        "    for i in range(len(fragments)):\n",
        "        current_iteration_next_candidates = []\n",
        "        \n",
        "        for order_candidate in order_candidates:\n",
        "            history = order_candidate ['history']\n",
        "            \n",
        "            \n",
        "            scored_next = [{'next_fragment':next_fragment, 'score':calc_perplexity_based_score(history, next_fragment.tokens)} for next_fragment in order_candidate['next_candidates']]\n",
        "            scored_next.sort(key=lambda x: x['score'], reverse=True)\n",
        "            \n",
        "            chosen_next_candidates = scored_next[:num_best_candidates] if len(scored_next) < num_best_candidates else scored_next\n",
        "            for chosen_next_candidate in chosen_next_candidates:\n",
        "                \n",
        "                next_step_beginning = copy(order_candidate['beginning'])\n",
        "                next_step_beginning.append(chosen_next_candidate['next_fragment'])\n",
        "                \n",
        "                next_step_probability = chosen_next_candidate['score']\n",
        "                \n",
        "                next_step_next_candidates = []\n",
        "                for next_step_next_candidate in order_candidate['next_candidates']:\n",
        "                    if next_step_next_candidate.fragment_id != chosen_next_candidate['next_fragment'].fragment_id:\n",
        "                        next_step_next_candidates.append(next_step_next_candidate)\n",
        "                next_step_history = history + chosen_next_candidate['next_fragment'].tokens\n",
        "                \n",
        "              \n",
        "                current_iteration_next_candidates.append({'beginning':next_step_beginning, 'next_candidates':next_step_next_candidates, 'probability':next_step_probability, 'history': next_step_history})\n",
        "        \n",
        "        current_iteration_next_candidates.sort(key=lambda x: x['probability'], reverse=True)\n",
        "       # print(len(current_iteration_next_candidates))\n",
        "        if current_iteration_next_candidates:\n",
        "            order_candidates = current_iteration_next_candidates[:num_best_candidates] if len(current_iteration_next_candidates) > num_best_candidates else  current_iteration_next_candidates\n",
        "    return [fragment.fragment_id for fragment in order_candidates[0]['beginning']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8msNHnMxGdI"
      },
      "source": [
        "import math\n",
        "FULL_LIMIT = GPT3_LIMIT\n",
        "def scoring_gpt_beam_search_last_score(test_sample,  num_best_candidates=2, epsilon=10**(-9)):\n",
        "    fragments = [Fragment(i, full_text = text) for i, text in enumerate(test_sample)]\n",
        "    \n",
        "    order_candidates = [{'beginning':[], 'next_candidates': fragments, 'probability':1, 'history':tokenizer.encode(start_token), 'aggregated_score': 0}]\n",
        "    random.shuffle(order_candidates[0]['next_candidates'])\n",
        "    \n",
        "    for i in range(len(fragments)):\n",
        "        current_iteration_next_candidates = []\n",
        "        \n",
        "        for order_candidate in order_candidates:\n",
        "            history = order_candidate ['history']\n",
        "            \n",
        "            \n",
        "            scored_next = [{'next_fragment':next_fragment, 'score':calc_perplexity_based_score(history, next_fragment.tokens)} for next_fragment in order_candidate['next_candidates']]\n",
        "            scored_next.sort(key=lambda x: x['score'], reverse=True)\n",
        "            \n",
        "            chosen_next_candidates = scored_next[:num_best_candidates] if len(scored_next) < num_best_candidates else scored_next\n",
        "            for chosen_next_candidate in chosen_next_candidates:\n",
        "                \n",
        "                next_step_beginning = copy(order_candidate['beginning'])\n",
        "                next_step_beginning.append(chosen_next_candidate['next_fragment'])\n",
        "                \n",
        "                next_step_probability = chosen_next_candidate['score']\n",
        "                \n",
        "                next_step_next_candidates = []\n",
        "                for next_step_next_candidate in order_candidate['next_candidates']:\n",
        "                    if next_step_next_candidate.fragment_id != chosen_next_candidate['next_fragment'].fragment_id:\n",
        "                        next_step_next_candidates.append(next_step_next_candidate)\n",
        "                next_step_history = history + chosen_next_candidate['next_fragment'].tokens\n",
        "                \n",
        "              \n",
        "                current_iteration_next_candidates.append({'beginning':next_step_beginning, 'next_candidates':next_step_next_candidates, 'probability':next_step_probability, 'history': next_step_history, 'aggregated_score': order_candidate['probability']+math.log(max(next_step_probability, epsilon))})\n",
        "        \n",
        "        current_iteration_next_candidates.sort(key=lambda x: x['probability'], reverse=True)\n",
        "       # print(len(current_iteration_next_candidates))\n",
        "        if current_iteration_next_candidates:\n",
        "            order_candidates = current_iteration_next_candidates[:num_best_candidates] if len(current_iteration_next_candidates) > num_best_candidates else  current_iteration_next_candidates\n",
        "    return {'order': [fragment.fragment_id for fragment in order_candidates[0]['beginning']], 'score': order_candidates[0]['aggregated_score']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wd6HSiAEzuyV"
      },
      "source": [
        "with open('sanity_check_data.json') as f:\n",
        "    sanity_check_data = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTDI3Qzgz3lM"
      },
      "source": [
        "real_quests_predictions = [scoring_gpt_beam_search_last_score(path) for path in sanity_check_data['real']]\n",
        "random_quests_predictions = [scoring_gpt_beam_search_last_score(path) for path in sanity_check_data['random']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS8IP56w0C1P",
        "outputId": "4ab11378-71a0-4f6a-9923-32e327566d52"
      },
      "source": [
        "real_quests_predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'order': [6, 8, 5, 7, 3, 2, 4, 0, 1], 'score': -7.363732216211075},\n",
              " {'order': [0, 1, 2, 3], 'score': -7.802377976082989},\n",
              " {'order': [3, 4, 13, 17, 16, 14, 10, 15, 11, 2, 1, 8, 9, 12, 7, 6, 0, 5],\n",
              "  'score': -7.485924463321846},\n",
              " {'order': [9, 4, 6, 8, 1, 5, 7, 3, 0, 2], 'score': -6.794129321447051},\n",
              " {'order': [4, 7, 10, 0, 14, 2, 13, 15, 8, 1, 11, 5, 9, 6, 3, 16, 12, 18, 17],\n",
              "  'score': -5.547068385159401}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuU4P68x0EFY",
        "outputId": "5d03608d-687c-48f4-aeeb-71a1e80bbb8a"
      },
      "source": [
        "from statistics import mean\n",
        "mean([sample['score'] for sample in real_quests_predictions])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-6.998646472444473"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srn6cuWW0O6m",
        "outputId": "fc9d80ba-c841-465a-bef8-726de5d6faa9"
      },
      "source": [
        "mean([sample['score'] for sample in random_quests_predictions])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-7.3518664475229984"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DXmiAdHguwM",
        "outputId": "ed7a153e-bd43-4336-9845-dfce2e32f075"
      },
      "source": [
        "FULL_LIMIT = GPT3_LIMIT\n",
        "\n",
        "results = []\n",
        "fails = []\n",
        "for file_name in tqdm(os.listdir(NEW_GRAPHS_DIRECTORY)):\n",
        "    used_current_file_paths = 0\n",
        "    graph_file = os.path.join(NEW_GRAPHS_DIRECTORY, file_name)\n",
        "    with open(graph_file) as f:\n",
        "        G = json_graph.node_link_graph(json.load(f))\n",
        "        nodes = G.nodes()\n",
        "\n",
        "    paths_file = os.path.join(NEW_PATHS_DIRECTORY, file_name)\n",
        "    with open(paths_file) as f:\n",
        "        paths = json.load(f)\n",
        "    \n",
        "    for path in paths:\n",
        "        corrected_path = [node_id for node_id in path if 'fragment_text' in nodes[node_id] and isinstance(nodes[node_id]['fragment_text'], str)]\n",
        "        if len(corrected_path) > 3 and len(corrected_path) <= 25:\n",
        "            try:\n",
        "                predicted = gpt_beam_search_last_score(corrected_path, G)\n",
        "\n",
        "                results.append({'correct':path, 'predicted':predicted})\n",
        "                used_current_file_paths += 1\n",
        "                if len(results) % 10 == 0:\n",
        "                    with open('gpt3_ordering_2048_last.json', 'w') as f:\n",
        "                        json.dump(results, f)\n",
        "                if used_current_file_paths == 10:\n",
        "                    break\n",
        "            except Exception as e:\n",
        "                fails.append[(file_name, e)]\n",
        "                \n",
        "with open('gpt3_ordering_2048_last.json', 'w') as f:\n",
        "    json.dump(results, f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 34/34 [2:40:13<00:00, 282.75s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1t4graFoP6VU",
        "outputId": "e6c26e9f-682e-436c-bb45-c638df4c9dcb"
      },
      "source": [
        "with open('gpt3_ordering_2048_last.json') as f:\n",
        "   results = json.load(f)\n",
        "\n",
        "\n",
        "correct_first = 0\n",
        "for result in results:\n",
        "    if result['predicted'][0] == result['correct'][0]:\n",
        "        correct_first += 1\n",
        "correct_first/len(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.058823529411764705"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLEzRMqog-Tr",
        "outputId": "0cc5b883-f367-471e-fa36-93ea5a9784e5"
      },
      "source": [
        "with open('gpt3_ordering_2048_last.json') as f:\n",
        "   results = json.load(f)\n",
        "\n",
        "prelast = 0\n",
        "last = 0\n",
        "second = 0\n",
        "for result in results:\n",
        "    \n",
        "    if result['predicted'][-1] == result['correct'][-1]:\n",
        "        last += 1\n",
        "    if result['predicted'][-2] == result['correct'][-2]:\n",
        "        prelast += 1\n",
        "    if result['predicted'][1] == result['correct'][1]:\n",
        "        second += 1\n",
        "print(last/len(results))\n",
        "print(prelast/len(results))\n",
        "print(second/len(results))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.08597285067873303\n",
            "0.11312217194570136\n",
            "0.08144796380090498\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6-Rwub1JvHs"
      },
      "source": [
        "gpt_2048_df = pd.DataFrame(columns=['Fragment_length', 'Tau', 'Max correct sequence'])\n",
        "exceptions = []\n",
        "\n",
        "with open('gpt3_ordering_2048_last.json') as f:\n",
        "   results = json.load(f)\n",
        "\n",
        "for sample in results:\n",
        "    correct = sample['correct']\n",
        "    predicted = fix_prediction(sample['predicted'], correct)\n",
        "    tau = kendalltau(predicted, correct).correlation\n",
        "    lcs = longest_correct_subsequence(predicted, correct)\n",
        "    gpt_2048_df.loc[len(gpt_2048_df)] = [len(correct), tau, lcs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "HB3HvHfPKEhn",
        "outputId": "e536b1b1-ae1d-4450-f330-494734d00808"
      },
      "source": [
        "aggr_gpt2048 = gpt_2048_df.groupby('Fragment_length').describe()[[('Tau',  'count'), ('Tau',  'mean'),  ('Max correct sequence',  'mean')]]\n",
        "aggr_gpt2048"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">Tau</th>\n",
              "      <th>Max correct sequence</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fragment_length</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4.0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>-0.555556</td>\n",
              "      <td>1.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5.0</th>\n",
              "      <td>15.0</td>\n",
              "      <td>0.093333</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6.0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>-0.180952</td>\n",
              "      <td>1.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7.0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>-0.126984</td>\n",
              "      <td>1.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8.0</th>\n",
              "      <td>9.0</td>\n",
              "      <td>-0.039683</td>\n",
              "      <td>2.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9.0</th>\n",
              "      <td>16.0</td>\n",
              "      <td>-0.031250</td>\n",
              "      <td>1.812500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.0</th>\n",
              "      <td>23.0</td>\n",
              "      <td>0.109179</td>\n",
              "      <td>2.130435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11.0</th>\n",
              "      <td>19.0</td>\n",
              "      <td>0.087081</td>\n",
              "      <td>2.105263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12.0</th>\n",
              "      <td>32.0</td>\n",
              "      <td>0.103220</td>\n",
              "      <td>1.468750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13.0</th>\n",
              "      <td>21.0</td>\n",
              "      <td>0.101343</td>\n",
              "      <td>2.380952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14.0</th>\n",
              "      <td>13.0</td>\n",
              "      <td>0.019442</td>\n",
              "      <td>1.692308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15.0</th>\n",
              "      <td>11.0</td>\n",
              "      <td>0.007792</td>\n",
              "      <td>1.909091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16.0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>-0.078571</td>\n",
              "      <td>1.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17.0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>1.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18.0</th>\n",
              "      <td>8.0</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>2.125000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19.0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>-0.087719</td>\n",
              "      <td>2.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20.0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>2.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21.0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.019048</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22.0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.060606</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23.0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.169960</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24.0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.010870</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25.0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.088000</td>\n",
              "      <td>2.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26.0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.163077</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Tau           Max correct sequence\n",
              "                count      mean                 mean\n",
              "Fragment_length                                     \n",
              "4.0               3.0 -0.555556             1.666667\n",
              "5.0              15.0  0.093333             1.000000\n",
              "6.0               7.0 -0.180952             1.285714\n",
              "7.0               6.0 -0.126984             1.833333\n",
              "8.0               9.0 -0.039683             2.333333\n",
              "9.0              16.0 -0.031250             1.812500\n",
              "10.0             23.0  0.109179             2.130435\n",
              "11.0             19.0  0.087081             2.105263\n",
              "12.0             32.0  0.103220             1.468750\n",
              "13.0             21.0  0.101343             2.380952\n",
              "14.0             13.0  0.019442             1.692308\n",
              "15.0             11.0  0.007792             1.909091\n",
              "16.0              7.0 -0.078571             1.857143\n",
              "17.0              6.0  0.058824             1.333333\n",
              "18.0              8.0  0.117647             2.125000\n",
              "19.0              6.0 -0.087719             2.333333\n",
              "20.0              5.0 -0.021053             2.200000\n",
              "21.0              1.0 -0.019048             3.000000\n",
              "22.0              2.0  0.060606             2.000000\n",
              "23.0              2.0  0.169960             2.000000\n",
              "24.0              2.0 -0.010870             1.000000\n",
              "25.0              5.0  0.088000             2.200000\n",
              "26.0              2.0  0.163077             2.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3ohgVbRcQwt"
      },
      "source": [
        "with open('latex.txt', 'w') as f:\n",
        "  f.write(aggr_gpt2048.to_latex())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IQYyJwW9BGL"
      },
      "source": [
        "class Fragment4Bidirectional:\n",
        "    bof_token = 'BOF'\n",
        "    button_token = 'BUTTON'\n",
        "    input_token = 'INPUT'\n",
        "    default_input='Далее'\n",
        "\n",
        "    def __init__(self, fragment_id, graph=None, full_text = None):\n",
        "        self.fragment_id = fragment_id\n",
        "        if graph:\n",
        "            fragment_text = graph.nodes()[fragment_id]['fragment_text']\n",
        "            edges = graph.edges()\n",
        "            buttons =  [' '.join([self.button_token, edges[edge]['command']] + [self.default_input]) for edge in graph.out_edges(fragment_id)]\n",
        "            fragment_text_without_options = ' '.join([self.bof_token, fragment_text]) \n",
        "            if buttons:\n",
        "                fragment_text = fragment_text_without_options + ' '.join(buttons)\n",
        "        fragment_text = ' '.join([fragment_text, self.input_token, self.default_input])\n",
        "        self.tokens = tokenizer.encode(fragment_text)\n",
        "        self.tokens_without_options = tokenizer.encode(fragment_text_without_options)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zzo5pnMWJ6Hv"
      },
      "source": [
        "def gpt_beam_search_last_score_bidirectional(test_sample, quest_graph, num_best_candidates=2):\n",
        "    fragments = [Fragment4Bidirectional(node_id, quest_graph) for node_id in test_sample]\n",
        "    \n",
        "    order_candidates = [{\n",
        "        'beginning':[], \n",
        "        'ending':[],\n",
        "        'next_candidates': fragments, \n",
        "        'probability':1, \n",
        "        'history_start':tokenizer.encode(start_token),\n",
        "        'history_end': tokenizer.encode(end_token)}]\n",
        "    random.shuffle(order_candidates[0]['next_candidates'])\n",
        "    \n",
        "    for i in range(len(fragments)):\n",
        "        current_iteration_next_candidates = []\n",
        "        \n",
        "        for order_candidate in order_candidates:\n",
        "\n",
        "            inverted_direction = i%2 == 1\n",
        "\n",
        "            history_start = order_candidate ['history_start']\n",
        "            history_end = order_candidate ['history_end']\n",
        "            \n",
        "            if inverted_direction:\n",
        "                 if i >= 2:\n",
        "                     scored_next = [{'next_fragment':next_fragment, 'score':calc_perplexity_based_score(next_fragment.tokens, history_end)} for next_fragment in order_candidate['next_candidates']]\n",
        "                 else:\n",
        "                    scored_next = [{'next_fragment':next_fragment, 'score':calc_perplexity_based_score(next_fragment.tokens_without_options, history_end)} for next_fragment in order_candidate['next_candidates']]\n",
        "            else:\n",
        "                scored_next = [{'next_fragment':next_fragment, 'score':calc_perplexity_based_score(history_start, next_fragment.tokens)} for next_fragment in order_candidate['next_candidates']]\n",
        "            scored_next.sort(key=lambda x: x['score'], reverse=True)\n",
        "            \n",
        "            chosen_next_candidates = scored_next[:num_best_candidates] if len(scored_next) < num_best_candidates else scored_next\n",
        "            \n",
        "            for chosen_next_candidate in chosen_next_candidates:\n",
        "\n",
        "                if inverted_direction:\n",
        "                    next_step_beginning = order_candidate['beginning']\n",
        "                    next_step_ending = [chosen_next_candidate['next_fragment']] + order_candidate['ending']\n",
        "                else:\n",
        "                   next_step_beginning = copy(order_candidate['beginning'])\n",
        "                   next_step_beginning.append(chosen_next_candidate['next_fragment'])\n",
        "                   next_step_ending = order_candidate['ending']\n",
        "                \n",
        "                next_step_probability = chosen_next_candidate['score']\n",
        "                \n",
        "                next_step_next_candidates = []\n",
        "                for next_step_next_candidate in order_candidate['next_candidates']:\n",
        "                    if next_step_next_candidate.fragment_id != chosen_next_candidate['next_fragment'].fragment_id:\n",
        "                        next_step_next_candidates.append(next_step_next_candidate)\n",
        "\n",
        "                if inverted_direction:\n",
        "                    next_step_history_starty = history_start\n",
        "                    if i >= 2:\n",
        "                        next_step_history_end = chosen_next_candidate['next_fragment'].tokens + history_end\n",
        "                    else:\n",
        "                        next_step_history_end = chosen_next_candidate['next_fragment'].tokens_without_options + history_end\n",
        "                    \n",
        "                else:\n",
        "                    next_step_history_start = history_start + chosen_next_candidate['next_fragment'].tokens\n",
        "                    next_step_history_end = history_end\n",
        "                current_iteration_next_candidates.append({'beginning':next_step_beginning, 'ending':next_step_ending,'next_candidates':next_step_next_candidates, 'probability':next_step_probability, 'history_start': next_step_history_start, 'history_end': next_step_history_end})\n",
        "        current_iteration_next_candidates.sort(key=lambda x: x['probability'], reverse=True)\n",
        "       # print(len(current_iteration_next_candidates))\n",
        "        if current_iteration_next_candidates:\n",
        "            order_candidates = current_iteration_next_candidates[:num_best_candidates] if len(current_iteration_next_candidates) > num_best_candidates else  current_iteration_next_candidates\n",
        "    assert all([not i['next_candidates'] for i in order_candidates])\n",
        "    for order_candidate in order_candidates:\n",
        "        order_candidate['probability'] = calc_perplexity_based_score(order_candidate['history_start'], order_candidate['history_end'])\n",
        "    order_candidates.sort(key = lambda x: x['probability'], reverse=True)\n",
        "    return [fragment.fragment_id for fragment in order_candidates[0]['beginning']] + [fragment.fragment_id for fragment in order_candidates[0]['ending']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh5xBM82Gdv9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jjJm7sl_wvO"
      },
      "source": [
        "FULL_LIMIT = GPT3_LIMIT\n",
        "start_token = 'BOQ'\n",
        "end_token = 'EOQ'\n",
        "\n",
        "results = []\n",
        "fails = []\n",
        "for file_name in tqdm(os.listdir(NEW_GRAPHS_DIRECTORY)):\n",
        "    used_current_file_paths = 0\n",
        "    graph_file = os.path.join(NEW_GRAPHS_DIRECTORY, file_name)\n",
        "    with open(graph_file) as f:\n",
        "        G = json_graph.node_link_graph(json.load(f))\n",
        "        nodes = G.nodes()\n",
        "\n",
        "    paths_file = os.path.join(NEW_PATHS_DIRECTORY, file_name)\n",
        "    with open(paths_file) as f:\n",
        "        paths = json.load(f)\n",
        "    \n",
        "    for path in paths:\n",
        "\n",
        "        try:\n",
        "            corrected_path = [node_id for node_id in path if 'fragment_text' in nodes[node_id] and isinstance(nodes[node_id]['fragment_text'], str)]\n",
        "            if len(corrected_path) > 3 and len(corrected_path) <= 25:\n",
        "                predicted = gpt_beam_search_last_score_bidirectional(corrected_path, G)\n",
        "\n",
        "                results.append({'correct':path, 'predicted':predicted})\n",
        "                used_current_file_paths += 1\n",
        "                if len(results) % 10 == 0:\n",
        "                    with open('gpt3_ordering_2048_last_bidirectional.json', 'w') as f:\n",
        "                        json.dump(results, f)\n",
        "              \n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "         \n",
        "                \n",
        "with open('gpt3_ordering_2048_last_bidirectional.json', 'w') as f:\n",
        "    json.dump(results, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiSDi0VnMrM2"
      },
      "source": [
        "gpt_2048_df = pd.DataFrame(columns=['Fragment_length', 'Tau', 'Max correct sequence'])\n",
        "\n",
        "with open('gpt3_ordering_2048_last_bidirectional.json') as f:\n",
        "   results = json.load(f)\n",
        "\n",
        "for sample in results:\n",
        "    correct = sample['correct']\n",
        "    predicted = sample['predicted']\n",
        "    tau = kendalltau(predicted, correct).correlation\n",
        "    lcs = longest_correct_subsequence(predicted, correct)\n",
        "    gpt_2048_df.loc[len(gpt_2048_df)] = [len(correct), tau, lcs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpGPwgwcM2tP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "outputId": "5a11e434-93aa-4daa-d24d-543a642da6cd"
      },
      "source": [
        "aggr_gpt2048 = gpt_2048_df.groupby('Fragment_length').describe()[[('Tau',  'count'), ('Tau',  'mean'),  ('Max correct sequence',  'mean')]]\n",
        "aggr_gpt2048"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">Tau</th>\n",
              "      <th>Max correct sequence</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fragment_length</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4.0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5.0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6.0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.133333</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7.0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8.0</th>\n",
              "      <td>9.0</td>\n",
              "      <td>0.031746</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9.0</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.084444</td>\n",
              "      <td>1.480000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.0</th>\n",
              "      <td>28.0</td>\n",
              "      <td>0.146032</td>\n",
              "      <td>1.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11.0</th>\n",
              "      <td>21.0</td>\n",
              "      <td>0.139394</td>\n",
              "      <td>1.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12.0</th>\n",
              "      <td>56.0</td>\n",
              "      <td>-0.023268</td>\n",
              "      <td>1.267857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13.0</th>\n",
              "      <td>40.0</td>\n",
              "      <td>0.014744</td>\n",
              "      <td>1.975000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14.0</th>\n",
              "      <td>31.0</td>\n",
              "      <td>0.050691</td>\n",
              "      <td>1.806452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15.0</th>\n",
              "      <td>27.0</td>\n",
              "      <td>-0.068783</td>\n",
              "      <td>1.703704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16.0</th>\n",
              "      <td>35.0</td>\n",
              "      <td>0.007143</td>\n",
              "      <td>1.657143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17.0</th>\n",
              "      <td>30.0</td>\n",
              "      <td>0.055882</td>\n",
              "      <td>1.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18.0</th>\n",
              "      <td>30.0</td>\n",
              "      <td>0.001743</td>\n",
              "      <td>1.266667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19.0</th>\n",
              "      <td>20.0</td>\n",
              "      <td>-0.074269</td>\n",
              "      <td>1.850000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20.0</th>\n",
              "      <td>26.0</td>\n",
              "      <td>0.021053</td>\n",
              "      <td>1.692308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21.0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>-0.074603</td>\n",
              "      <td>2.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22.0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.151515</td>\n",
              "      <td>1.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23.0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>-0.133070</td>\n",
              "      <td>1.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24.0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.014493</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25.0</th>\n",
              "      <td>8.0</td>\n",
              "      <td>0.016667</td>\n",
              "      <td>1.750000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Tau           Max correct sequence\n",
              "                count      mean                 mean\n",
              "Fragment_length                                     \n",
              "4.0               2.0  0.333333             0.000000\n",
              "5.0               1.0 -0.200000             0.000000\n",
              "6.0               2.0 -0.133333             1.500000\n",
              "7.0               6.0  0.047619             1.500000\n",
              "8.0               9.0  0.031746             1.000000\n",
              "9.0              25.0  0.084444             1.480000\n",
              "10.0             28.0  0.146032             1.250000\n",
              "11.0             21.0  0.139394             1.571429\n",
              "12.0             56.0 -0.023268             1.267857\n",
              "13.0             40.0  0.014744             1.975000\n",
              "14.0             31.0  0.050691             1.806452\n",
              "15.0             27.0 -0.068783             1.703704\n",
              "16.0             35.0  0.007143             1.657143\n",
              "17.0             30.0  0.055882             1.600000\n",
              "18.0             30.0  0.001743             1.266667\n",
              "19.0             20.0 -0.074269             1.850000\n",
              "20.0             26.0  0.021053             1.692308\n",
              "21.0              6.0 -0.074603             2.166667\n",
              "22.0              5.0  0.151515             1.800000\n",
              "23.0              6.0 -0.133070             1.333333\n",
              "24.0              1.0  0.014493             2.000000\n",
              "25.0              8.0  0.016667             1.750000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0Pop2DJLITC"
      },
      "source": [
        "with open('bidirectional.txt', 'w') as f:\n",
        "  f.write(aggr_gpt2048.to_latex())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrvDMpaHQgW_",
        "outputId": "77687841-4e99-4db4-80c3-ec8a429b1bdb"
      },
      "source": [
        "with open('gpt3_ordering_2048_last_bidirectional.json') as f:\n",
        "   results = json.load(f)\n",
        "\n",
        "\n",
        "correct_first = 0\n",
        "correct_last = 0\n",
        "for result in results:\n",
        "    if result['predicted'][0] == result['correct'][0]:\n",
        "        correct_first += 1\n",
        "    if result['predicted'][-1] == result['correct'][-1]:\n",
        "        correct_last += 1\n",
        "print(correct_first/len(results))\n",
        "print(correct_last/len(results))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.025842696629213482\n",
            "0.15842696629213482\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1fLgkR3gFdn",
        "outputId": "3cd18e9e-134e-4348-88c7-68c35710f358"
      },
      "source": [
        "prelast = 0\n",
        "second = 0\n",
        "for result in results:\n",
        "    if result['predicted'][-2] == result['correct'][-2]:\n",
        "        prelast += 1\n",
        "    if result['predicted'][1] == result['correct'][1]:\n",
        "        second += 1\n",
        "print(prelast/len(results))\n",
        "print(second/len(results))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.12247191011235956\n",
            "0.16067415730337078\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}