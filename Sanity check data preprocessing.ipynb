{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import networkx as nx\n",
    "from networkx import json_graph\n",
    "import stanza\n",
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "# a list of selected paths. We do not publish texts according to the copyright\n",
    "from data import SELECTED_REAL_PATHS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-24 19:46:50 INFO: Loading these models for language: ru (Russian):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | syntagrus |\n",
      "| pos       | syntagrus |\n",
      "| lemma     | syntagrus |\n",
      "| depparse  | syntagrus |\n",
      "| ner       | wikiner   |\n",
      "=========================\n",
      "\n",
      "2021-05-24 19:46:50 INFO: Use device: cpu\n",
      "2021-05-24 19:46:50 INFO: Loading: tokenize\n",
      "2021-05-24 19:46:50 INFO: Loading: pos\n",
      "2021-05-24 19:46:51 INFO: Loading: lemma\n",
      "2021-05-24 19:46:52 INFO: Loading: depparse\n",
      "2021-05-24 19:46:53 INFO: Loading: ner\n",
      "2021-05-24 19:47:01 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_GRAPHS_DIR = 'D:\\\\Диплом_текстовые_квесты\\\\Data\\\\new_questbook_graphs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alien_The_Last_Escape.json',\n",
       " 'cyberpunk.json',\n",
       " 'game10034.json',\n",
       " 'game10075.json',\n",
       " 'game10078.json',\n",
       " 'game10092.json',\n",
       " 'game10099.json',\n",
       " 'game10106.json',\n",
       " 'game10120.json',\n",
       " 'game10163.json',\n",
       " 'game10164.json',\n",
       " 'game10225.json',\n",
       " 'game10229.json',\n",
       " 'game10234.json',\n",
       " 'game10302.json',\n",
       " 'game10365.json',\n",
       " 'game9464.json',\n",
       " 'game9723.json',\n",
       " 'game9771.json',\n",
       " 'game9776.json',\n",
       " 'game9800.json',\n",
       " 'game9816.json',\n",
       " 'game9963.json',\n",
       " 'game9974.json',\n",
       " 'Gmanjob.json',\n",
       " 'Ksnsndkj223.json',\n",
       " 'Luna-park_dlya_smelchakov.json',\n",
       " 'NSS.json',\n",
       " 'ostrov_osminogov.json',\n",
       " 'Peshchera_Vremeni.json',\n",
       " 'prosto2002.json',\n",
       " 'Puteshestviye_na_dno_morya_.json',\n",
       " 'Tesskyrim.json',\n",
       " 'V_poyezde_s_vampirami.json']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(NEW_GRAPHS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:\\\\Диплом_текстовые_квесты\\\\Data\\\\new_questbook_graphs\\\\Alien_The_Last_Escape.json') as f:\n",
    "    test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['directed', 'multigraph', 'graph', 'nodes', 'links'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fragment_text': 'Дорогие друзья!\\nПеред вами сторигейм - [b]Чужой: Последний выход[/b].\\nОн создан по мотивам фильма и книги \"Чужой\", и повествует альтернативную историю о встрече Ностромо с LV-426.',\n",
       " 'id': '38e6c3ca-5be5-11eb-bd01-002590e2f74e'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['nodes'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_data(graphs_directory, length):\n",
    "    chosen_quests_files = random.choices(os.listdir(graphs_directory), k=length)\n",
    "    random_data = []\n",
    "    for chosen_quest_file in chosen_quests_files:\n",
    "        with open(os.path.join(graphs_directory, chosen_quest_file)) as f:\n",
    "            graph_data = json.load(f)\n",
    "            random.shuffle(graph_data['nodes'])\n",
    "            for node in graph_data['nodes']:\n",
    "                if 'fragment_text' in node and isinstance(node['fragment_text'], str) and node['fragment_text'].strip():\n",
    "                    random_data.append(node['fragment_text'])\n",
    "                    break\n",
    "    return random_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data = []\n",
    "for real_path in SELECTED_REAL_PATHS:\n",
    "    random_data.append(generate_random_data(NEW_GRAPHS_DIR, len(real_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:\\\\Диплом_текстовые_квесты\\\\Квесты, отобранные для оценки адекватности\\\\sanity_check_data.json', 'w') as f:\n",
    "    json.dump(\n",
    "        {\n",
    "        'real': SELECTED_REAL_PATHS,\n",
    "        'random': random_data\n",
    "        },\n",
    "    f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:\\\\Диплом_текстовые_квесты\\\\Квесты, отобранные для оценки адекватности\\\\sanity_check_data.json') as f:\n",
    "    sanity_check_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2json(word:stanza.models.common.doc.Word):\n",
    "    word_json = {}\n",
    "    for field in ['text','lemma', 'upos', \"feats\", 'deprel']:\n",
    "        word_json[field] = getattr(word, field)\n",
    "    return word_json\n",
    "\n",
    "def dependency2json(dependency):\n",
    "    return [word2json(dependency[0]), dependency[1], word2json(dependency[2])]\n",
    "\n",
    "def text2nouns_and_verbs_data(text):\n",
    "    nouns = []\n",
    "    pronouns = []\n",
    "    verbal_deps = []\n",
    "    if isinstance(text, str):\n",
    "        for sent in nlp(text).sentences:\n",
    "            sent_nouns = [word2json(dependency[2]) for dependency in sent.dependencies if dependency[2].upos in ['NOUN', 'PROPN']]\n",
    "            nouns += sent_nouns\n",
    "            sent_pronouns = [word2json(dependency[2]) for dependency in sent.dependencies if dependency[2].upos == \"PRON\"]\n",
    "            pronouns += sent_pronouns\n",
    "            sent_verbal_deps = [dependency2json(dependency) for dependency in sent.dependencies if dependency[2].upos == \"VERB\"]\n",
    "            verbal_deps += sent_verbal_deps\n",
    "    return {'nouns': nouns, 'pronouns': pronouns, 'verbal_deps': verbal_deps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pseudograph(sequence):\n",
    "    graph = nx.Graph()\n",
    "    for i, text in enumerate(sequence):\n",
    "        graph.add_node(i, joined_text=text, joined_morphodata=text2nouns_and_verbs_data(text))\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = create_pseudograph(sanity_check_data['real'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_tag(fragment_noun_tags):\n",
    "    if 'subject' in fragment_noun_tags:\n",
    "        return 'subject'\n",
    "    elif 'object' in fragment_noun_tags:\n",
    "        return 'object'\n",
    "    else:\n",
    "        return 'other_dep'\n",
    "\n",
    "def quest_path2entity_graph(texts):\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    noun_lemmas_counter = Counter()\n",
    "    \n",
    "    morphograph = create_pseudograph(texts)\n",
    "    path = list(range(len(texts)))\n",
    "    nodes = morphograph.nodes()\n",
    "    \n",
    "    node2chosen_syntactic_tags = {}\n",
    "    nouns2nodes = defaultdict(set)\n",
    "    morphology_key = 'joined_morphodata'\n",
    "    text_key = 'joined_text'\n",
    "    for node in path:\n",
    "        current_node2all_syntactic_tags = defaultdict(set)\n",
    "        for noun_data in nodes[node][morphology_key]['nouns']:\n",
    "            noun_lemma = noun_data['lemma']\n",
    "            noun_lemmas_counter.update([noun_lemma])\n",
    "            nouns2nodes['noun_'+noun_lemma].add(node)\n",
    "            dep_type = 'other_dep'\n",
    "            dependency = noun_data['deprel']\n",
    "            if 'subj' in dependency:\n",
    "                dep_type = 'subject'\n",
    "            elif 'obj' in dependency:\n",
    "                dep_type = 'object'\n",
    "            current_node2all_syntactic_tags[noun_lemma].add(dep_type)\n",
    "        \n",
    "        node2chosen_syntactic_tags[node] = {noun:choose_tag(current_node2all_syntactic_tags[noun]) for noun in current_node2all_syntactic_tags}\n",
    "        \n",
    "    relevant_nouns = [noun for noun in noun_lemmas_counter if noun_lemmas_counter[noun]>1]\n",
    "    G.add_node('global', fragment_text='UNK')\n",
    "    for relevant_noun in relevant_nouns:\n",
    "        G.add_node('noun_'+relevant_noun, fragment_text=relevant_noun)\n",
    "    for node in path:\n",
    "        G.add_node(node, fragment_text=nodes[node][text_key])\n",
    "        G.add_edge(node, 'global', label='global')\n",
    "        for noun, syntactic_role in node2chosen_syntactic_tags[node].items():\n",
    "            if noun in relevant_nouns:\n",
    "                G.add_edge(node, 'noun_'+noun, label=syntactic_role)\n",
    "    for noun in nouns2nodes:\n",
    "        entity_neighbours = itertools.combinations(nouns2nodes[noun], 2)\n",
    "        for pair in entity_neighbours:\n",
    "            G.add_edge(*pair, label='fragments_pair')\n",
    "    return G, [['noun_'+relevant_noun for relevant_noun in relevant_nouns]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts2graph_data(texts):\n",
    "    path = list(range(len(texts)))\n",
    "    G, nouns = quest_path2entity_graph(texts)\n",
    "    \n",
    "    return ['_', path, json_graph.node_link_data(G), nouns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_sanity_check_data = {\n",
    "    'real': [texts2graph_data(texts) for texts in sanity_check_data['real']],\n",
    "    'random': [texts2graph_data(texts) for texts in sanity_check_data['random']]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:\\\\Диплом_текстовые_квесты\\\\Квесты, отобранные для оценки адекватности\\\\sanity_check_data_entity_graph.json', 'w') as f:\n",
    "    json.dump(prepared_sanity_check_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_random = json_graph.node_link_graph(prepared_sanity_check_data['random'][0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
